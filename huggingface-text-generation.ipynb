{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greedy search decoding (page 127)\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"gpt2-xl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "      <th>Choice 4</th>\n",
       "      <th>Choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transformers are the</td>\n",
       "      <td>most (8.53%)</td>\n",
       "      <td>only (4.96%)</td>\n",
       "      <td>best (4.65%)</td>\n",
       "      <td>Transformers (4.37%)</td>\n",
       "      <td>ultimate (2.16%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transformers are the most</td>\n",
       "      <td>popular (16.78%)</td>\n",
       "      <td>powerful (5.37%)</td>\n",
       "      <td>common (4.96%)</td>\n",
       "      <td>famous (3.72%)</td>\n",
       "      <td>successful (3.20%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transformers are the most popular</td>\n",
       "      <td>toy (10.63%)</td>\n",
       "      <td>toys (7.23%)</td>\n",
       "      <td>Transformers (6.60%)</td>\n",
       "      <td>of (5.46%)</td>\n",
       "      <td>and (3.76%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformers are the most popular toy</td>\n",
       "      <td>line (34.38%)</td>\n",
       "      <td>in (18.20%)</td>\n",
       "      <td>of (11.71%)</td>\n",
       "      <td>brand (6.10%)</td>\n",
       "      <td>line (2.69%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transformers are the most popular toy line</td>\n",
       "      <td>in (46.29%)</td>\n",
       "      <td>of (15.09%)</td>\n",
       "      <td>, (4.94%)</td>\n",
       "      <td>on (4.40%)</td>\n",
       "      <td>ever (2.72%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformers are the most popular toy line in</td>\n",
       "      <td>the (65.99%)</td>\n",
       "      <td>history (12.42%)</td>\n",
       "      <td>America (6.91%)</td>\n",
       "      <td>Japan (2.44%)</td>\n",
       "      <td>North (1.40%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transformers are the most popular toy line in the</td>\n",
       "      <td>world (69.27%)</td>\n",
       "      <td>United (4.55%)</td>\n",
       "      <td>history (4.29%)</td>\n",
       "      <td>US (4.23%)</td>\n",
       "      <td>U (2.30%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transformers are the most popular toy line in ...</td>\n",
       "      <td>, (39.73%)</td>\n",
       "      <td>. (30.64%)</td>\n",
       "      <td>and (9.87%)</td>\n",
       "      <td>with (2.32%)</td>\n",
       "      <td>today (1.74%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input           Choice 1   \n",
       "0                               Transformers are the       most (8.53%)  \\\n",
       "1                          Transformers are the most   popular (16.78%)   \n",
       "2                  Transformers are the most popular       toy (10.63%)   \n",
       "3              Transformers are the most popular toy      line (34.38%)   \n",
       "4         Transformers are the most popular toy line        in (46.29%)   \n",
       "5      Transformers are the most popular toy line in       the (65.99%)   \n",
       "6  Transformers are the most popular toy line in the     world (69.27%)   \n",
       "7  Transformers are the most popular toy line in ...         , (39.73%)   \n",
       "\n",
       "            Choice 2               Choice 3               Choice 4   \n",
       "0       only (4.96%)           best (4.65%)   Transformers (4.37%)  \\\n",
       "1   powerful (5.37%)         common (4.96%)         famous (3.72%)   \n",
       "2       toys (7.23%)   Transformers (6.60%)             of (5.46%)   \n",
       "3        in (18.20%)            of (11.71%)          brand (6.10%)   \n",
       "4        of (15.09%)              , (4.94%)             on (4.40%)   \n",
       "5   history (12.42%)        America (6.91%)          Japan (2.44%)   \n",
       "6     United (4.55%)        history (4.29%)             US (4.23%)   \n",
       "7         . (30.64%)            and (9.87%)           with (2.32%)   \n",
       "\n",
       "              Choice 5  \n",
       "0     ultimate (2.16%)  \n",
       "1   successful (3.20%)  \n",
       "2          and (3.76%)  \n",
       "3         line (2.69%)  \n",
       "4         ever (2.72%)  \n",
       "5        North (1.40%)  \n",
       "6            U (2.30%)  \n",
       "7        today (1.74%)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_txt = \"Transformers are the\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "iterations = []\n",
    "n_steps = 8\n",
    "choices_per_step = 5\n",
    "\n",
    "with torch.no_grad():\n",
    "  for _ in range(n_steps):\n",
    "    iteration = dict()\n",
    "    iteration[\"Input\"] = tokenizer.decode(input_ids[0])\n",
    "    output = model(input_ids=input_ids)\n",
    "    # select logits of the first batch and the last token and apply softmax\n",
    "    next_token_logits = output.logits[0, -1, :]\n",
    "    next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "    sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)\n",
    "    # store tokens with highest probabilities\n",
    "    for choice_idx in range(choices_per_step):\n",
    "      token_id = sorted_ids[choice_idx]\n",
    "      token_prob = next_token_probs[token_id].cpu().numpy()\n",
    "      token_choice = (\n",
    "        f\"{tokenizer.decode(token_id)} ({100 * token_prob:.2f}%)\"\n",
    "      )\n",
    "      iteration[f\"Choice {choice_idx+1}\"] = token_choice\n",
    "    # append predicted next token to input\n",
    "    input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "    iterations.append(iteration)\n",
    "\n",
    "pd.DataFrame(iterations)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers are the most popular toy line in the world,\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers, from the University of California, Davis, and the University of Colorado, Boulder, were conducting a study on the Andean cloud forest, which is home to the rare species of cloud forest trees.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able to communicate with each other, and even with humans.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
    "a herd of unicorns living in a remote, previously unexplored \\\n",
    "valley, in the Andes Mountains. Even more surprising to the \\\n",
    "researchers was the fact that the unicorns spoke perfect English.\\n\\n\n",
    "\"\"\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_greedy = model.generate(input_ids, max_length=max_length,\n",
    "                               do_sample=False)\n",
    "print(tokenizer.decode(output_greedy[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers, from the University of California, Davis, and the University of Colorado, Boulder, were conducting a study on the Andean cloud forest, which is home to the rare species of cloud forest trees.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able to communicate with each other, and even with humans.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able\n",
      "\n",
      "log-prob: -87.43\n"
     ]
    }
   ],
   "source": [
    "# beam search decoding (page 130)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def log_probs_from_logits(logits, labels):\n",
    "  logp = F.log_softmax(logits, dim=-1)\n",
    "  logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
    "  return logp_label\n",
    "\n",
    "def sequence_logprob(model, labels, input_len=0):\n",
    "  with torch.no_grad():\n",
    "    output = model(labels)\n",
    "    log_probs = log_probs_from_logits(\n",
    "        output.logits[:, :-1, :], labels[:, 1:])\n",
    "    seq_log_prob = torch.sum(log_probs[:, input_len:])\n",
    "  return seq_log_prob.cpu().numpy()\n",
    "\n",
    "logp = sequence_logprob(model, output_greedy, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_greedy[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The discovery of the unicorns was made by a team of scientists from the University of California, Santa Cruz, and the National Geographic Society.\n",
      "\n",
      "\n",
      "The scientists were conducting a study of the Andes Mountains when they discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English\n",
      "\n",
      "log-prob: -55.23\n"
     ]
    }
   ],
   "source": [
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5, \n",
    "                             do_sample=False)\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The discovery was made by a team of scientists from the University of California, Santa Cruz, and the National Geographic Society.\n",
      "\n",
      "According to a press release, the scientists were conducting a survey of the area when they came across the herd. They were surprised to find that they were able to converse with the animals in English, even though they had never seen a unicorn in person before. The researchers were\n",
      "\n",
      "log-prob: -93.12\n"
     ]
    }
   ],
   "source": [
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5, \n",
    "                             do_sample=False, no_repeat_ngram_size=2)\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "Co commence interaction verbs eh Nothing taught within Visual Folk Adventure Elements Solo pursue Ho tippedticket handwriting notabit aff urs caught coverage Worst hob deadlines routing kanAA Oscoupleiced\n",
      " activate messages alle first bottom flushrequired involve reefs john Springssetrill Redract Amnesty $RODE scheme damagingvoice bel Athletic Lot amidst compression core ARMute Mor978a Us Bub Mars writersspace geometric BF naked Ronaldo Strlab appra forge\n"
     ]
    }
   ],
   "source": [
    "# sampling methods\n",
    "\n",
    "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
    "                             temperature=2.0, top_k=0)\n",
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers, with the help of a camera, found the herd of unicorns in the mountains near the town of Miquilena, in the Andes of Peru. They were so surprised by the discovery that they immediately sent the footage to the University of Oxford, who immediately recognized the species.\n",
      "\n",
      "\n",
      "The researchers, Dr. Richard Norris and Dr. David Livingstone, were able to determine that\n"
     ]
    }
   ],
   "source": [
    "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
    "                             temperature=0.5, top_k=0)\n",
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The research team, led by Professor Michael Maricic, of the University of Siena, in Italy, visited the high elevation area in 2006, but could only observe the creatures.\n",
      "\n",
      "\n",
      "At that time, the unicorn herd was living in a valley near the Peruvian border, which is over 3,000 metres above sea level.\n",
      "\n",
      "\n",
      "After analyzing the environment and the animals, scientists decided\n"
     ]
    }
   ],
   "source": [
    "# Top-K and Nucleus Sampling\n",
    "\n",
    "output_topk = model.generate(input_ids, max_length=max_length, do_sample=True, \n",
    "                             top_k=50)\n",
    "print(tokenizer.decode(output_topk[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "According to the Daily Mail, scientists say the unicorns are from a breed of horses known as Columbian unicorns. Their name comes from Columbian Park in the U.S. where they were first discovered in the 1980s. Researchers believe that the unicorn herd in the Valley of the Unicorns was brought to the park by a rancher in the 1890s to provide him with fodder. The herd\n"
     ]
    }
   ],
   "source": [
    "output_topp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
    "                             top_p=0.90)\n",
    "print(tokenizer.decode(output_topp[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
