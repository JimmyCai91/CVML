{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import warnings \n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_bikes = pd.read_csv('./bike_rentals_cleaned.csv')\n",
    "X_bikes = df_bikes.iloc[:,:-1]\n",
    "y_bikes = df_bikes.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bikes, y_bikes, \n",
    "                                                    random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_1 = DecisionTreeRegressor(max_depth=2, random_state=2)\n",
    "tree_1.fit(X_train, y_train)\n",
    "y_train_pred = tree_1.predict(X_train)\n",
    "y2_train = y_train - y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_2 = DecisionTreeRegressor(max_depth=2, random_state=2)\n",
    "tree_2.fit(X_train, y2_train)\n",
    "y2_train_pred = tree_2.predict(X_train)\n",
    "y3_train = y2_train - y2_train_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_3 = DecisionTreeRegressor(max_depth=2, random_state=2)\n",
    "tree_3.fit(X_train, y3_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred = tree_1.predict(X_test)\n",
    "y2_pred = tree_2.predict(X_test)\n",
    "y3_pred = tree_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y1_pred + y2_pred + y3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911.0479538776444"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "MSE(y_test, y_pred) ** .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911.0479538776439"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor(max_depth=2, n_estimators=3, random_state=2,\n",
    "                                learning_rate=1.0)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "MSE(y_test, y_pred) ** .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857.1072323426944"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=2, n_estimators=30, \n",
    "                                random_state=2, learning_rate=1.0)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "MSE(y_test, y_pred) ** .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936.3617413678853"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=2, n_estimators=300, \n",
    "                                random_state=2, learning_rate=1.0)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "MSE(y_test, y_pred) ** .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653.7456840231495"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=2, n_estimators=300, \n",
    "                                random_state=2)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "MSE(y_test, y_pred) ** .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001, Score: 1633.0261400367258\n",
      "Learning Rate: 0.01, Score: 831.5430182728547\n",
      "Learning Rate: 0.05, Score: 685.0192988749717\n",
      "Learning Rate: 0.1, Score: 653.7456840231495\n",
      "Learning Rate: 0.15, Score: 687.666134269379\n",
      "Learning Rate: 0.2, Score: 664.312804425697\n",
      "Learning Rate: 0.3, Score: 689.4190385930236\n",
      "Learning Rate: 0.5, Score: 693.8856905068778\n",
      "Learning Rate: 1.0, Score: 936.3617413678853\n"
     ]
    }
   ],
   "source": [
    "learning_rate_values = [0.001, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.5, 1.0]\n",
    "for value in learning_rate_values:\n",
    "  gbr = GradientBoostingRegressor(max_depth=2, n_estimators=300, \n",
    "                                random_state=2, learning_rate=value)\n",
    "  gbr.fit(X_train, y_train)\n",
    "  y_pred = gbr.predict(X_test)\n",
    "  rmse = MSE(y_test, y_pred) ** .5\n",
    "  print(f\"Learning Rate: {value}, Score: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: None, Score: 869.2788645118395\n",
      "Max Depth: 1, Score: 707.8261886858736\n",
      "Max Depth: 2, Score: 653.7456840231495\n",
      "Max Depth: 3, Score: 646.4045923317708\n",
      "Max Depth: 4, Score: 663.048387855927\n"
     ]
    }
   ],
   "source": [
    "depths = [None, 1, 2, 3, 4]\n",
    "for depth in depths:\n",
    "  gbr = GradientBoostingRegressor(max_depth=depth, n_estimators=300, \n",
    "                                  random_state=2)\n",
    "  gbr.fit(X_train, y_train)\n",
    "  y_pred = gbr.predict(X_test)\n",
    "  rmse = MSE(y_test, y_pred) ** 0.5\n",
    "  print(f\"Max Depth: {depth}, Score: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample: 1, Score: 646.4045923317708\n",
      "Subsample: 0.9, Score: 620.1819001443569\n",
      "Subsample: 0.8, Score: 617.2355650565677\n",
      "Subsample: 0.7, Score: 612.9879156983139\n",
      "Subsample: 0.6, Score: 622.6385116402317\n",
      "Subsample: 0.5, Score: 626.9974073227554\n"
     ]
    }
   ],
   "source": [
    "samples = [1, 0.9, 0.8, .7, .6, .5]\n",
    "for sample in samples:\n",
    "  gbr = GradientBoostingRegressor(max_depth=3, n_estimators=300, \n",
    "                                  subsample=sample, random_state=2)\n",
    "  gbr.fit(X_train, y_train)\n",
    "  y_pred = gbr.predict(X_test)\n",
    "  rmse = MSE(y_test, y_pred) ** 0.5\n",
    "  print(f\"Subsample: {sample}, Score: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'subsample': 0.65, 'n_estimators': 300, 'learning_rate': 0.05}\n",
      "Training score: 636.200\n",
      "Test set score: 625.985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {'subsample': [0.65, 0.70, 0.75], \n",
    "          'n_estimators': [300, 500, 1000], \n",
    "          'learning_rate': [0.05, 0.075, 0.1]}\n",
    "gbr = GradientBoostingRegressor(max_depth=3, random_state=2)\n",
    "rand_reg = RandomizedSearchCV(gbr, params, n_iter=10, \n",
    "                              scoring='neg_mean_squared_error', cv=5, \n",
    "                              n_jobs=-1, random_state=2)\n",
    "rand_reg.fit(X_train, y_train)\n",
    "best_model = rand_reg.best_estimator_\n",
    "best_params = rand_reg.best_params_\n",
    "print(\"Best params:\", best_params)\n",
    "best_score = np.sqrt(-rand_reg.best_score_)\n",
    "print(\"Training score: {:.3f}\".format(best_score))\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse_test = MSE(y_test, y_pred)**0.5\n",
    "print('Test set score: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596.9544588974487"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=3, n_estimators=1600, \n",
    "                                  subsample=0.75, learning_rate=0.02,\n",
    "                                  random_state=2)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "MSE(y_test, y_pred) ** .5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584.3395337495713"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xg_reg = XGBRegressor(max_depth=3, n_estimators=1600, eta=0.02, \n",
    "                      subsample=0.75, random_state=2)\n",
    "xg_reg.fit(X_train, y_train)\n",
    "y_pred = xg_reg.predict(X_test)\n",
    "MSE(y_test, y_pred) ** .5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approaching big data -- gradient boosting versus XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7   \n",
       "0      2    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18  \\\n",
       "1      2   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2      2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3      2   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4      2 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "\n",
       "    FLUX.8  FLUX.9  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191   \n",
       "0   -96.27  -79.89  ...     -78.07    -102.15    -102.15      25.13  \\\n",
       "1   -85.33  -83.97  ...      -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56  ...     -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42  ...       5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57  ...    -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./exoplanets.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5087 entries, 0 to 5086\n",
      "Columns: 3198 entries, LABEL to FLUX.3197\n",
      "dtypes: float64(3197), int64(1)\n",
      "memory usage: 124.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.iloc[:,1:], df.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5087 entries, 0 to 5086\n",
      "Columns: 3198 entries, LABEL to FLUX.3197\n",
      "dtypes: float64(3197), int64(1)\n",
      "memory usage: 124.1 MB\n",
      "\n",
      "Run Time: 0.0468754768371582 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time \n",
    "\n",
    "start = time.time()\n",
    "df.info()\n",
    "end = time.time()\n",
    "elapsed = end - start \n",
    "print(f\"\\nRun Time: {elapsed} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9874213836477987\n",
      "\n",
      "Run Time: 629.8467800617218 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbr = GradientBoostingClassifier(n_estimators=100, max_depth=2, \n",
    "                                 random_state=2)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(f\"Score: {score}\")\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(f\"\\nRun Time: {elapsed} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9913522012578616\n",
      "\n",
      "Run Time: 36.13928723335266 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "xg_reg = XGBClassifier(n_estimators=100, max_depth=2, \n",
    "                       random_state=2)\n",
    "xg_reg.fit(X_train, y_train - 1)\n",
    "y_pred = xg_reg.predict(X_test)\n",
    "score = accuracy_score(y_pred, y_test - 1)\n",
    "print(f\"Score: {score}\")\n",
    "end = time.time()\n",
    "elapsed = end - start \n",
    "print(f\"\\nRun Time: {elapsed} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
